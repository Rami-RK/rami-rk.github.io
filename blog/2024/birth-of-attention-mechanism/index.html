<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Birth of Attention Mechanism | Ramendra Kumar </title> <meta name="author" content="Ramendra Kumar"> <meta name="description" content="The evolution of attention in sequence-to-sequence models."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://rami-rk.github.io/blog/2024/birth-of-attention-mechanism/"> <script src="/assets/js/theme.js?v=48c9b5bd7f2e0605e39e579400e22553"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Birth of Attention Mechanism",
            "description": "The evolution of attention in sequence-to-sequence models.",
            "published": "March 26, 2024",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ramendra</span> Kumar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Birth of Attention Mechanism</h1> <p>The evolution of attention in sequence-to-sequence models.</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#overview">Overview</a> </div> <div> <a href="#lets-see-the-decoder-in-detail">Lets See the Decoder in Detail</a> </div> <div> <a href="#what-goes-into-the-bottom-of-the-decoder-rnn-unit">What Goes Into the Bottom of the Decoder RNN Unit</a> </div> <div> <a href="#problem-with-seq2seq">Problem With Seq2Seq</a> </div> <div> <a href="#to-solve-this-problem-attention-is-originated-for-seq2seq">To Solve This Problem: Attention is Originated for Seq2Seq</a> </div> <div> <a href="#improved-encoder-decoder-architecture-with-attention">Improved Encoder-Decoder Architecture With Attention</a> </div> <div> <a href="#context-vector">Context Vector</a> </div> <div> <a href="#calculating-attention-weights">Calculating Attention Weights</a> </div> </nav> </d-contents> <h2 id="overview">Overview</h2> <p>The onset of ChatGPT and open-source LLMs has changed how we work across industries, but transformer-based models power the magic behind BERT, GPT, and other large language models. This post is part of a series to explain Transformers step by step:</p> <ol> <li>The Birth of Attention Mechanism</li> <li>Self-Attention</li> <li>Transformer Architecture</li> </ol> <p>We start with the attention mechanism in the context of language translation using a seq2seq (encoder-decoder) architecture. In the example below, a Hindi sentence (in Devanagari) is fed into an encoder and decoded into English as “I love to eat.”</p> <p>The encoder ingests the input and computes hidden states \(h(1), h(2), \dots, h(T)\), returning a final hidden state \(h(T)\). This vector is a compressed representation of the input sequence (often called a “thought vector”) and becomes the input to the decoder.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/birth-of-attention-mechanism/enc_dec_rnn-480.webp 480w,/assets/img/birth-of-attention-mechanism/enc_dec_rnn-800.webp 800w,/assets/img/birth-of-attention-mechanism/enc_dec_rnn-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/birth-of-attention-mechanism/enc_dec_rnn.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Figure 1</figcaption> </figure> <hr> <h2 id="lets-see-the-decoder-in-detail">Lets See the Decoder in Detail</h2> <p>Every RNN unit has two sources of input: the current input and the previous hidden state. The decoder is an RNN that uses the encoder output \(h(T)\) as its initial hidden state. Its job is to decompress the input representation into the target sequence.</p> <hr> <h2 id="what-goes-into-the-bottom-of-the-decoder-rnn-unit">What Goes Into the Bottom of the Decoder RNN Unit</h2> <p>At the beginning, a special token <code class="language-plaintext highlighter-rouge">\&lt;SOS&gt;</code> indicates the start of the sequence. The decoder predicts the first word, feeds it back as input, and continues until it produces the end token. This is an autoregressive (causal) process. In practice, training requires paired input-output sentence data.</p> <hr> <h2 id="problem-with-seq2seq">Problem With Seq2Seq</h2> <ol> <li>Every input sequence is compressed into a single fixed-size vector \(h(T)\). For long sentences, that vector must remember too much.</li> <li>Humans do not translate by remembering entire sentences at once; we focus on relevant parts as we go.</li> </ol> <hr> <h2 id="to-solve-this-problem-attention-is-originated-for-seq2seq">To Solve This Problem: Attention is Originated for Seq2Seq</h2> <p>The idea is to let each output word attend to the most relevant parts of the input.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/birth-of-attention-mechanism/attention_def-480.webp 480w,/assets/img/birth-of-attention-mechanism/attention_def-800.webp 800w,/assets/img/birth-of-attention-mechanism/attention_def-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/birth-of-attention-mechanism/attention_def.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Figure 2</figcaption> </figure> <p>Consider an input sentence (in Hindi) that translates to “I am going to play.” The list \(t_1\) contains attention values for the first output word, \(t_2\) for the second, and so on. Each list represents how much the output should focus on each input word.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/birth-of-attention-mechanism/attention_values-480.webp 480w,/assets/img/birth-of-attention-mechanism/attention_values-800.webp 800w,/assets/img/birth-of-attention-mechanism/attention_values-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/birth-of-attention-mechanism/attention_values.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Figure 3</figcaption> </figure> <p>For the first output word, we might focus on just the first input token; later steps may focus on different or multiple input tokens. This is exactly what standard seq2seq fails to do, since each step only sees the same final encoder state.</p> <hr> <h2 id="improved-encoder-decoder-architecture-with-attention">Improved Encoder-Decoder Architecture With Attention</h2> <p>Instead of feeding only the final encoder state to the decoder, we provide all encoder hidden states to each decoder step and learn attention weights (alphas) that determine how much each input should contribute.</p> <p>For output at time step \(t = 2\):</p> <p>\(\alpha_{2,1} \text{ is the weight on input 1}\) \(\alpha_{2,2} \text{ is the weight on input 2}\) \(\alpha_{2,3} \text{ is the weight on input 3}\) \(\alpha_{2,4} \text{ is the weight on input 4}\)</p> <p>Similarly, for output at time step \(t = 4\):</p> \[\alpha_{4,1}, \alpha_{4,2}, \alpha_{4,3}, \alpha_{4,4}\] <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/birth-of-attention-mechanism/rnn_with_attention-480.webp 480w,/assets/img/birth-of-attention-mechanism/rnn_with_attention-800.webp 800w,/assets/img/birth-of-attention-mechanism/rnn_with_attention-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/birth-of-attention-mechanism/rnn_with_attention.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Figure 4</figcaption> </figure> <hr> <h2 id="context-vector">Context Vector</h2> <p>Define the weighted combination as a context vector. For output at time step 4:</p> \[C(4) = \alpha_{4,1} h(1) + \alpha_{4,2} h(2) + \alpha_{4,3} h(3) + \alpha_{4,4} h(4)\] <p>In general:</p> \[C(i) = \sum_{j=1}^{T_x} \alpha_{i,j} h(j)\] <p>The context vector is simply the weighted sum of encoder hidden states. The weights are the attention scores.</p> <hr> <h2 id="calculating-attention-weights">Calculating Attention Weights</h2> <p>We introduce an alignment score \(e_{i,j}\): at the \(i^\text{th}\) decoder step, how important is the \(j^\text{th}\) input word. This depends on the decoder state and the encoder hidden state:</p> \[e_{i,j} = f(S_{i-1}, h_j)\] <p>We then normalize these scores with SoftMax to form a probability distribution over input tokens:</p> \[\alpha_{i,j} = \frac{\exp(e_{i,j})}{\sum_{k=1}^{T} \exp(e_{i,k})}\] <p>The attention weight \(\alpha_{i,j}\) is the probability of focusing on the \(j^\text{th}\) input word when producing the \(i^\text{th}\) output word.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2" target="_blank" rel="external nofollow noopener">Displaying External Posts on Your al-folio Blog</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/self-attention/">Self Attention</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/photo-gallery/">a post with image galleries</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/tabs/">a post with tabs</a> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Ramendra Kumar. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=6f508d74becd347268a7f822bca7309d"></script> </body> </html>