<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Normal Distribution | Ramendra Kumar </title> <meta name="author" content="Ramendra Kumar"> <meta name="description" content="From Histogram to Normal Distribution."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://rami-rk.github.io/blog/2025/normal-distribution/"> <script src="/assets/js/theme.js?v=48c9b5bd7f2e0605e39e579400e22553"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Normal Distribution",
            "description": "From Histogram to Normal Distribution.",
            "published": "May 02, 2025",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ramendra</span> Kumar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About Me </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search (Ctrl+K)" onclick="openSearchModal()"> <span class="nav-link"><i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Normal Distribution</h1> <p>From Histogram to Normal Distribution.</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#standard-normal">Standard Normal</a> </div> <div> <a href="#normal-random-variable">Normal Random Variable</a> </div> <div> <a href="#role-of-sigma">Role of Sigma</a> </div> <div> <a href="#examples-of-normal-distribution">Examples of Normal Distribution</a> </div> <div> <a href="#how-does-it-fit-into-learning-aiml">How does it fit into learning AIML?</a> </div> </nav> </d-contents> <p>Let’s continue with the case study of shaft length that we saw in the continuous distribution explanation. We were given lengths of 100 samples of shafts with a manufacturing tolerance of 0.1 mm, meaning the actual length will be within the range of 100 ± 0.1 mm. We divided the range [99.90, 100.10] into several equal segments and plotted the number of length values that reside in these segments. We had a bar-like graph called a histogram. It shows the frequency of the values that occur in different segments. We further modified it by dividing the frequency within each segment by the total sample count, which is 100. The final plot is shown below:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/random_variable_and_distribution/histogram-480.webp 480w,/assets/img/random_variable_and_distribution/histogram-800.webp 800w,/assets/img/random_variable_and_distribution/histogram-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/random_variable_and_distribution/histogram.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Figure 1</figcaption> </figure> <p>We can approximate this distribution with the bell-shaped curve shown below, and we will call this distribution as following Normal distribution.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/random_variable_and_distribution/histogram_with_bell_curve-480.webp 480w,/assets/img/random_variable_and_distribution/histogram_with_bell_curve-800.webp 800w,/assets/img/random_variable_and_distribution/histogram_with_bell_curve-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/random_variable_and_distribution/histogram_with_bell_curve.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Figure 2</figcaption> </figure> <p>Now observe that most of the sample lengths are centered around a mean of approximately 100 mm and spread on both sides almost symmetrically. The ideal Normal distribution assumes a bell-shaped curve that is symmetrical around the mean value with a certain variance.</p> <p>Normal random variables, also often called Gaussian random variables, are perhaps the most important ones in probability theory. They are prevalent in applications for two reasons: they have useful analytical properties, and they are the most common model for random noise. In general, they are a good model of noise or randomness whenever that noise is due to the addition of many small independent noise terms, and this is a very common situation in the real world.</p> <p>We define normal random variables by specifying their PDFs as they are continuous distributions. We start with the simplest case, known as standard normal. The standard normal is denoted using the shorthand notation given below, and we will see shortly why this notation is used.</p> <hr> <h3 id="standard-normal">Standard Normal</h3> \[\mathcal{N}(0,1): \quad f_x(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}\] <p>This PDF is defined for all values of x, meaning x can be any real number i.e. this random variable can take values anywhere on the real line. Let us try to understand this formula.</p> <p>It includes the exponential of \(-\frac{x^2}{2}\) (negative x squared over 2). If we are to plot the function \(\frac{x^2}{2}\), it has a shape of the form shown below left, and it is centered at zero.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/random_variable_and_distribution/standard_normal_distribution-480.webp 480w,/assets/img/random_variable_and_distribution/standard_normal_distribution-800.webp 800w,/assets/img/random_variable_and_distribution/standard_normal_distribution-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/random_variable_and_distribution/standard_normal_distribution.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Figure 3</figcaption> </figure> <p>But then we take the negative exponential of this function. When you take the negative exponential, the value becomes small whenever \(\frac{x^2}{2}\) is large. Therefore, the negative exponential equals 1 when x is 0. As x increases and \(x^2\) also increases, the negative exponential decreases. Thus, we obtain a shape like the one shown on the top right in red colour, which is symmetrical on both sides.</p> <p>Finally, there is the constant \(\frac{1}{\sqrt{2\pi}}\): Where is this constant coming from? Well, there is a useful but somewhat complex calculus exercise that shows that the integral from minus infinity to plus infinity of \(e^{-\frac{x^2}{2}}\) is equal to \(\sqrt{2\pi}\).</p> <p>I.e. \(\int_{-\infty}^{+\infty} e^{-\frac{x^2}{2}} \, dx = \sqrt{2\pi}\)</p> <p>Now, we need a PDF that integrates to 1, meaning the area under the PDF curve should be 1. To achieve this, we include this constant in front of the expression so that the integral equals 1. This explains the presence of this particular constant.</p> <p><strong>What is the mean of this random variable?</strong></p> <p>Since \(x^2\) is symmetric around 0, and for this reason, the PDF itself is symmetric around 0. Therefore, by symmetry, the mean has to be equal to 0 or expectation: \(E[X] = 0\). This explains the entry zero in first position of standard normal notation: \(\mathcal{N}(0,1)\).</p> <p><strong>How about the variance?</strong></p> <p>To calculate the variance, you need to solve a calculus problem involving integration by parts. After completing the calculation, you find that the variance is equal to 1 or \(\text{var}(X) = 1\). This explains the entry one in the notation of standard normal: \(\mathcal{N}(0,1)\).</p> <hr> <h3 id="normal-random-variable">Normal Random Variable</h3> <p><strong>General Normal (Gaussian) random variables</strong></p> <p>Let us now define general normal random variables. General normal random variables are specified their corresponding PDF as given below, which is more complex, and involves two parameters: \(\mu\), and \(\sigma^2\), where sigma is a positive parameter, \(\sigma &gt; 0\).</p> \[\mathcal{N}(\mu, \sigma^2): \quad f_x(x) = \frac{1}{\sigma \sqrt{2\pi}} \, e^{-\frac{(x-\mu)^2}{2\sigma^2}}\] <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/random_variable_and_distribution/normal_distribution-480.webp 480w,/assets/img/random_variable_and_distribution/normal_distribution-800.webp 800w,/assets/img/random_variable_and_distribution/normal_distribution-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/random_variable_and_distribution/normal_distribution.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Figure 4</figcaption> </figure> <p>Once again, it will have a bell shape, but this bell is no longer symmetric around 0, and its width can be controlled.</p> <p>To understand the form of this PDF, let’s first focus on the exponent, just as we did with the standard normal case. The exponent is quadratic and is centered at \(x = \mu\). It vanishes when \(x = \mu\) and becomes positive elsewhere. The curve is shown below in red. Taking the negative exponential of this quadratic results in a function that is highest at \(x = \mu\) and decreases as we move further away from \(\mu\) shown by purple colour.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/random_variable_and_distribution/normal_distribution2-480.webp 480w,/assets/img/random_variable_and_distribution/normal_distribution2-800.webp 800w,/assets/img/random_variable_and_distribution/normal_distribution2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/random_variable_and_distribution/normal_distribution2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Figure 5</figcaption> </figure> <p><strong>What is the mean of this random variable?</strong></p> <p>Since the exponent term is symmetric around \(\mu\), the PDF is also symmetric around \(\mu\), and therefore, the mean is also equal to \(\mu\), i.e. \(E[X] = \mu\).</p> <p><strong>What about the variance?</strong></p> <p>It turns out– and this is a calculus exercise that we will omit– that the variance of this PDF is equal to \(\sigma^2\), i.e. \(\text{var}(x) = \sigma^2\).</p> <p>This explains the notation: \(\mathcal{N}(\mu, \sigma^2)\), which indicates that we are dealing with a normal distribution with a mean of \(\mu\), and a variance of \(\sigma^2\).</p> <hr> <h3 id="role-of-sigma">Role of Sigma</h3> <p>We mentioned that in a general normal distribution, the width of the bell curve can be controlled, and this is the role of \(\sigma\) in the PDF. The figure below shows three normal curves with the same mean value of 0.5 but different \(\sigma\) values of 0.25, 0.5, and 0.75, respectively. We can clearly see that as \(\sigma\) increases, the width of the curve also increases.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/random_variable_and_distribution/role_of_sigma-480.webp 480w,/assets/img/random_variable_and_distribution/role_of_sigma-800.webp 800w,/assets/img/random_variable_and_distribution/role_of_sigma-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/random_variable_and_distribution/role_of_sigma.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Figure 6</figcaption> </figure> <hr> <h3 id="examples-of-normal-distribution">Examples of Normal Distribution</h3> <p>Many processes in nature result in events that follow a normal distribution. Height, weight, Test Scores, and even Measurement Errors are modeled by the normal distribution. In general, variables that can be modeled as a sum of many independent processes always follow normal distributions.</p> <p>However, not all natural processes follow a normal distribution; some may follow other distributions depending on the underlying factors and their interactions viz. Earthquakes, Population Growth, Disease Outbreaks etc don’t follow normal distributions.</p> <hr> <h3 id="how-does-it-fit-into-learning-aiml">How does it fit into learning AIML?</h3> <p>Many machine learning algorithms have underlying assumptions of normal distributions. For example, Linear Regression and Logistic Regression assume normally distributed residuals and log-odds, respectively, for accurate inference. Gaussian Naive Bayes relies on the normal distribution for feature classification. The Central Limit Theorem supports using the normal distribution for sampling means. Techniques such as z-score normalization in feature scaling, and Gaussian Mixture Models for clustering often assume normality.</p> <p>Additionally, neural networks use the normal distribution for weight initialization and batch normalization, while anomaly detection utilizes Gaussian models to identify deviations from normal behavior.</p> <p>Thus, the normal distribution is pervasive in AI and ML, often operating behind the scenes.</p> <div class="support-section"> <h3>Support My Work</h3> <p> If you found this article helpful, consider buying me a coffee! Your support helps me create more content. </p> <a href="https://ramenkarna.gumroad.com/coffee" target="_blank" rel="noopener" class="support-button"> <i class="fa-solid fa-mug-hot"></i> Buy Me a Coffee </a> </div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4" style="margin-top: 1.5rem;">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/continuous-distribution/">Continuous Distribution &amp; PDF</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/random-variables/">Random Variables</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/understanding-derivatives/">Understanding Derivatives</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/self-attention/">Self Attention</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/transformer-architecture/">Transformer Model Architecture</a> </li> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Ramendra Kumar. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-0CKQ8QPL30"></script> <script defer src="/assets/js/google-analytics-setup.js"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=6f508d74becd347268a7f822bca7309d"></script> </body> </html>